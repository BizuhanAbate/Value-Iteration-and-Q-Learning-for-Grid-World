{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "8NGyK4gTRl-A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define grid world parameters\n",
        "GRID_SIZE = 5\n",
        "ACTIONS = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # Up, Down, Left, Right\n",
        "GAMMA = 0.9  # Discount factor\n",
        "THRESHOLD = 1e-4  # Convergence threshold\n",
        "REWARD_STEP = -1\n",
        "REWARD_GOAL = 10\n",
        "GOAL_STATE = (4, 4)"
      ],
      "metadata": {
        "id": "3iBPiM_4RneC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize value function\n",
        "V = np.zeros((GRID_SIZE, GRID_SIZE))"
      ],
      "metadata": {
        "id": "kfDJwhX8RpXe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xONFDrBGRiGz"
      },
      "outputs": [],
      "source": [
        "# Value Iteration Algorithm\n",
        "def value_iteration():\n",
        "    while True:\n",
        "        delta = 0  # To check for convergence\n",
        "        new_V = np.copy(V)\n",
        "\n",
        "        for i in range(GRID_SIZE):\n",
        "            for j in range(GRID_SIZE):\n",
        "                if (i, j) == GOAL_STATE:\n",
        "                    continue  # Goal state remains unchanged\n",
        "\n",
        "                max_value = float('-inf')\n",
        "                for action in ACTIONS:\n",
        "                    ni, nj = i + action[0], j + action[1]\n",
        "\n",
        "                    # Stay within bounds\n",
        "                    if 0 <= ni < GRID_SIZE and 0 <= nj < GRID_SIZE:\n",
        "                        value = REWARD_STEP + GAMMA * V[ni, nj]\n",
        "                    else:\n",
        "                        value = REWARD_STEP + GAMMA * V[i, j]  # If hitting wall, stay in place\n",
        "\n",
        "                    max_value = max(max_value, value)\n",
        "\n",
        "                new_V[i, j] = max_value\n",
        "                delta = max(delta, abs(new_V[i, j] - V[i, j]))\n",
        "\n",
        "        V[:] = new_V  # Update values\n",
        "        if delta < THRESHOLD:\n",
        "            break  # Convergence reached"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract optimal policy\n",
        "def extract_policy():\n",
        "    policy = np.full((GRID_SIZE, GRID_SIZE), ' ', dtype='<U1')\n",
        "    action_symbols = {(-1, 0): '^', (1, 0): 'v', (0, -1): '<', (0, 1): '>'}\n",
        "\n",
        "    for i in range(GRID_SIZE):\n",
        "        for j in range(GRID_SIZE):\n",
        "            if (i, j) == GOAL_STATE:\n",
        "                policy[i, j] = 'G'\n",
        "                continue\n",
        "\n",
        "            best_action = None\n",
        "            best_value = float('-inf')\n",
        "\n",
        "            for action in ACTIONS:\n",
        "                ni, nj = i + action[0], j + action[1]\n",
        "                if 0 <= ni < GRID_SIZE and 0 <= nj < GRID_SIZE:\n",
        "                    value = V[ni, nj]\n",
        "                else:\n",
        "                    value = V[i, j]  # If hitting wall, stay in place\n",
        "\n",
        "                if value > best_value:\n",
        "                    best_value = value\n",
        "                    best_action = action\n",
        "\n",
        "            policy[i, j] = action_symbols[best_action]\n",
        "\n",
        "    return policy\n"
      ],
      "metadata": {
        "id": "VHSnbMaZRyXd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Value Iteration\n",
        "value_iteration()\n",
        "optimal_policy = extract_policy()\n",
        "\n",
        "# Print Optimal Policy\n",
        "for row in optimal_policy:\n",
        "    print(' '.join(row))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCSpvvhoRuHE",
        "outputId": "8ae81b78-ff3d-4d7e-9e13-63bafcf1e73b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v v v v v\n",
            "v v v v v\n",
            "v v v v v\n",
            "v v v v v\n",
            "> > > > G\n"
          ]
        }
      ]
    }
  ]
}